{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "pycharm-43a80b0",
      "language": "python",
      "display_name": "PyCharm (ProgettoDLA-Puglisi-)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Benchmarker.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gkLYv6HBM4j6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLqUgMAyQ9Xk"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QT-7Ab32M4j7"
      },
      "source": [
        "Blinks = np.load('/content/drive/MyDrive/DLA/npy/Blinks_F3.npy')\n",
        "Labels = np.load('/content/drive/MyDrive/DLA/npy/Labels_F3.npy')\n",
        "BlinksTest = np.load('/content/drive/MyDrive/DLA/npy/BlinksTest_F3.npy')\n",
        "LabelsTest = np.load('/content/drive/MyDrive/DLA/npy/LabelsTest_F3.npy')\n",
        "    #deciding the indices of each video based on the fold\n",
        "    #####################Normalizing the input#############Second phase\n",
        "BlinksTest[:,:,0]=(BlinksTest[:,:,0]-np.mean(Blinks[:,:,0]))/np.std(Blinks[:,:,0])\n",
        "Blinks[:,:,0]=(Blinks[:,:,0]-np.mean(Blinks[:,:,0]))/np.std(Blinks[:,:,0])\n",
        "    #####\n",
        "    #####\n",
        "BlinksTest[:,:,1]=(BlinksTest[:,:,1]-np.mean(Blinks[:,:,1]))/np.std(Blinks[:,:,1])\n",
        "Blinks[:,:,1]=(Blinks[:,:,1]-np.mean(Blinks[:,:,1]))/np.std(Blinks[:,:,1])\n",
        "    #####\n",
        "BlinksTest[:,:,2]=(BlinksTest[:,:,2]-np.mean(Blinks[:,:,2]))/np.std(Blinks[:,:,2])\n",
        "Blinks[:,:,2]=(Blinks[:,:,2]-np.mean(Blinks[:,:,2]))/np.std(Blinks[:,:,2])\n",
        "    #####\n",
        "BlinksTest[:,:,3]=(BlinksTest[:,:,3]-np.mean(Blinks[:,:,3]))/np.std(Blinks[:,:,3])\n",
        "Blinks[:,:,3]=(Blinks[:,:,3]-np.mean(Blinks[:,:,3]))/np.std(Blinks[:,:,3])\n",
        "    ####\n",
        "    ####JUST TO DOUBLE CHECK\n",
        "    ####\n",
        "    # print(np.mean(Blinks[:,:,0]),np.mean(Blinks[:,:,1]),np.mean(Blinks[:,:,2]),np.mean(Blinks[:,:,3]))\n",
        "    # print(np.std(Blinks[:,:,0]),np.std(Blinks[:,:,1]),np.std(Blinks[:,:,2]),np.std(Blinks[:,:,3]))\n",
        "    # print(np.mean(BlinksTest[:,:,0]),np.mean(BlinksTest[:,:,1]),np.mean(BlinksTest[:,:,2]),np.mean(BlinksTest[:,:,3]))\n",
        "    # print(np.std(BlinksTest[:,:,0]),np.std(BlinksTest[:,:,1]),np.std(BlinksTest[:,:,2]),np.std(BlinksTest[:,:,3]))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXPk40ffK_iw"
      },
      "source": [
        "#BinarizationLabels\r\n",
        "LabelsTest[LabelsTest==10] = 1\r\n",
        "Labels[Labels==10] = 1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4QvMI1ELM4j8"
      },
      "source": [
        "def create_model(model_name):\n",
        "    if model_name == 'LSTMreza':\n",
        "      input = tf.keras.Input(shape=(30, 4))\n",
        "      x = tf.keras.layers.Dense(64, activation='relu')(input)\n",
        "      x = tf.keras.layers.Masking(mask_value=0.0)(x)\n",
        "      x = tf.keras.layers.LSTM(32, return_sequences=False,dropout=0.1, recurrent_dropout=0.1)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(8, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.1)(x)\n",
        "      y = tf.keras.layers.Dense(1, activation='tanh')(x)\n",
        "      model = tf.keras.models.Model(inputs=[input], outputs=[y])\n",
        "    elif model_name == 'LSTM':\n",
        "      input = tf.keras.Input(shape=(30, 4))\n",
        "      x = tf.keras.layers.Masking(mask_value=0.0)(input)\n",
        "      x = tf.keras.layers.LSTM(32, return_sequences=False,dropout=0.1, recurrent_dropout=0.1)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.5)(x)\n",
        "      y = tf.keras.layers.Dense(1, activation='tanh')(x)\n",
        "      model = tf.keras.models.Model(inputs=[input], outputs=[y])\n",
        "    elif model_name == 'stackedreza':\n",
        "      input = tf.keras.Input(shape=(30, 4))\n",
        "      x = tf.keras.layers.Dense(64, activation='relu')(input)\n",
        "      x = tf.keras.layers.Masking(mask_value=0.0)(x)\n",
        "      rnn_cells = [tf.keras.layers.LSTMCell(32) for _ in range(4)]\n",
        "      stacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)\n",
        "      x = tf.keras.layers.RNN(stacked_lstm)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(8, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.1)(x)\n",
        "      y = tf.keras.layers.Dense(1, activation='tanh')(x)\n",
        "      model = tf.keras.models.Model(inputs=[input], outputs=[y])\n",
        "    else:\n",
        "      print(\"Chiama le cose con il loro nome\")\n",
        "    return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTyY8Q7WQWAe"
      },
      "source": [
        "model_name = \"stackedreza\"\r\n",
        "model = create_model(model_name)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6zYeqvFQaBl",
        "outputId": "c1e7cb17-becc-4e08-9899-10af2239a768"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 30, 4)]           0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 30, 64)            320       \n",
            "_________________________________________________________________\n",
            "masking_5 (Masking)          (None, 30, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 13,681\n",
            "Trainable params: 13,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08YWVpLJQjgB"
      },
      "source": [
        "lr = 0.000053\r\n",
        "bs = 64\r\n",
        "ep = 100\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \r\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\r\n",
        "              metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt592QOSQn4V",
        "outputId": "776bc492-c33c-4c7f-e7ee-0e2bb0b04dfa"
      },
      "source": [
        "model.fit(x= Blinks, y = Labels, validation_data=(BlinksTest, LabelsTest), epochs=ep, batch_size=bs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "121/121 [==============================] - 10s 54ms/step - loss: 1.5181 - accuracy: 0.4545 - val_loss: 1.0196 - val_accuracy: 0.2999\n",
            "Epoch 2/100\n",
            "121/121 [==============================] - 6s 49ms/step - loss: 1.0495 - accuracy: 0.4643 - val_loss: 0.7216 - val_accuracy: 0.6459\n",
            "Epoch 3/100\n",
            "121/121 [==============================] - 6s 49ms/step - loss: 0.8336 - accuracy: 0.5048 - val_loss: 0.5836 - val_accuracy: 0.6877\n",
            "Epoch 4/100\n",
            "121/121 [==============================] - 6s 49ms/step - loss: 0.7442 - accuracy: 0.5511 - val_loss: 0.5230 - val_accuracy: 0.7117\n",
            "Epoch 5/100\n",
            "121/121 [==============================] - 6s 49ms/step - loss: 0.7023 - accuracy: 0.5570 - val_loss: 0.5007 - val_accuracy: 0.7312\n",
            "Epoch 6/100\n",
            "121/121 [==============================] - 6s 49ms/step - loss: 0.6982 - accuracy: 0.5619 - val_loss: 0.4896 - val_accuracy: 0.7494\n",
            "Epoch 7/100\n",
            "121/121 [==============================] - 6s 49ms/step - loss: 0.6910 - accuracy: 0.5640 - val_loss: 0.4803 - val_accuracy: 0.7614\n",
            "Epoch 8/100\n",
            "121/121 [==============================] - 6s 49ms/step - loss: 0.6917 - accuracy: 0.5684 - val_loss: 0.4732 - val_accuracy: 0.7717\n",
            "Epoch 9/100\n",
            "121/121 [==============================] - 6s 48ms/step - loss: 0.6767 - accuracy: 0.5704 - val_loss: 0.4706 - val_accuracy: 0.7761\n",
            "Epoch 10/100\n",
            "121/121 [==============================] - 6s 48ms/step - loss: 0.6709 - accuracy: 0.5774 - val_loss: 0.4688 - val_accuracy: 0.7757\n",
            "Epoch 11/100\n",
            " 45/121 [==========>...................] - ETA: 3s - loss: 0.6725 - accuracy: 0.5690"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xuvcjppj167k",
        "outputId": "fe1b4a98-f294-4d4b-e95f-4a4e143e88f9"
      },
      "source": [
        "model.fit(x= Blinks, y = Labels, validation_data=(BlinksTest, LabelsTest), epochs=100, batch_size=128)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6880 - accuracy: 0.5636 - val_loss: 0.4776 - val_accuracy: 0.7730\n",
            "Epoch 2/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6883 - accuracy: 0.5671 - val_loss: 0.4763 - val_accuracy: 0.7757\n",
            "Epoch 3/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6840 - accuracy: 0.5707 - val_loss: 0.4744 - val_accuracy: 0.7761\n",
            "Epoch 4/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6862 - accuracy: 0.5657 - val_loss: 0.4733 - val_accuracy: 0.7770\n",
            "Epoch 5/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6840 - accuracy: 0.5698 - val_loss: 0.4719 - val_accuracy: 0.7770\n",
            "Epoch 6/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6884 - accuracy: 0.5619 - val_loss: 0.4707 - val_accuracy: 0.7770\n",
            "Epoch 7/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6859 - accuracy: 0.5729 - val_loss: 0.4692 - val_accuracy: 0.7783\n",
            "Epoch 8/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6811 - accuracy: 0.5733 - val_loss: 0.4679 - val_accuracy: 0.7770\n",
            "Epoch 9/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6784 - accuracy: 0.5715 - val_loss: 0.4662 - val_accuracy: 0.7774\n",
            "Epoch 10/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6762 - accuracy: 0.5704 - val_loss: 0.4648 - val_accuracy: 0.7801\n",
            "Epoch 11/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6761 - accuracy: 0.5706 - val_loss: 0.4631 - val_accuracy: 0.7792\n",
            "Epoch 12/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6789 - accuracy: 0.5664 - val_loss: 0.4616 - val_accuracy: 0.7801\n",
            "Epoch 13/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6712 - accuracy: 0.5821 - val_loss: 0.4597 - val_accuracy: 0.7805\n",
            "Epoch 14/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6692 - accuracy: 0.5777 - val_loss: 0.4582 - val_accuracy: 0.7828\n",
            "Epoch 15/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6652 - accuracy: 0.5817 - val_loss: 0.4564 - val_accuracy: 0.7823\n",
            "Epoch 16/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6768 - accuracy: 0.5706 - val_loss: 0.4546 - val_accuracy: 0.7841\n",
            "Epoch 17/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6683 - accuracy: 0.5799 - val_loss: 0.4528 - val_accuracy: 0.7850\n",
            "Epoch 18/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6685 - accuracy: 0.5822 - val_loss: 0.4510 - val_accuracy: 0.7850\n",
            "Epoch 19/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6653 - accuracy: 0.5840 - val_loss: 0.4490 - val_accuracy: 0.7859\n",
            "Epoch 20/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6645 - accuracy: 0.5827 - val_loss: 0.4468 - val_accuracy: 0.7881\n",
            "Epoch 21/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6610 - accuracy: 0.5869 - val_loss: 0.4449 - val_accuracy: 0.7876\n",
            "Epoch 22/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6632 - accuracy: 0.5887 - val_loss: 0.4428 - val_accuracy: 0.7916\n",
            "Epoch 23/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6638 - accuracy: 0.5866 - val_loss: 0.4405 - val_accuracy: 0.7965\n",
            "Epoch 24/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6639 - accuracy: 0.5880 - val_loss: 0.4378 - val_accuracy: 0.7988\n",
            "Epoch 25/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6552 - accuracy: 0.5913 - val_loss: 0.4354 - val_accuracy: 0.8010\n",
            "Epoch 26/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6569 - accuracy: 0.5936 - val_loss: 0.4326 - val_accuracy: 0.8041\n",
            "Epoch 27/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6545 - accuracy: 0.5955 - val_loss: 0.4296 - val_accuracy: 0.8059\n",
            "Epoch 28/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6578 - accuracy: 0.5915 - val_loss: 0.4257 - val_accuracy: 0.8090\n",
            "Epoch 29/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6533 - accuracy: 0.5976 - val_loss: 0.4230 - val_accuracy: 0.8112\n",
            "Epoch 30/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6510 - accuracy: 0.5994 - val_loss: 0.4196 - val_accuracy: 0.8134\n",
            "Epoch 31/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6510 - accuracy: 0.5985 - val_loss: 0.4156 - val_accuracy: 0.8143\n",
            "Epoch 32/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6490 - accuracy: 0.6088 - val_loss: 0.4125 - val_accuracy: 0.8147\n",
            "Epoch 33/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6483 - accuracy: 0.6033 - val_loss: 0.4084 - val_accuracy: 0.8210\n",
            "Epoch 34/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6412 - accuracy: 0.6193 - val_loss: 0.4048 - val_accuracy: 0.8187\n",
            "Epoch 35/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6397 - accuracy: 0.6144 - val_loss: 0.4010 - val_accuracy: 0.8187\n",
            "Epoch 36/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6376 - accuracy: 0.6143 - val_loss: 0.3979 - val_accuracy: 0.8143\n",
            "Epoch 37/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6377 - accuracy: 0.6184 - val_loss: 0.3917 - val_accuracy: 0.8214\n",
            "Epoch 38/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6323 - accuracy: 0.6223 - val_loss: 0.3866 - val_accuracy: 0.8223\n",
            "Epoch 39/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6298 - accuracy: 0.6245 - val_loss: 0.3828 - val_accuracy: 0.8205\n",
            "Epoch 40/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6304 - accuracy: 0.6284 - val_loss: 0.3809 - val_accuracy: 0.8183\n",
            "Epoch 41/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6248 - accuracy: 0.6326 - val_loss: 0.3741 - val_accuracy: 0.8223\n",
            "Epoch 42/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6229 - accuracy: 0.6348 - val_loss: 0.3733 - val_accuracy: 0.8179\n",
            "Epoch 43/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6210 - accuracy: 0.6346 - val_loss: 0.3651 - val_accuracy: 0.8276\n",
            "Epoch 44/100\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 0.6248 - accuracy: 0.6352 - val_loss: 0.3681 - val_accuracy: 0.8183\n",
            "Epoch 45/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6170 - accuracy: 0.6404 - val_loss: 0.3626 - val_accuracy: 0.8219\n",
            "Epoch 46/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6135 - accuracy: 0.6514 - val_loss: 0.3595 - val_accuracy: 0.8254\n",
            "Epoch 47/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.6115 - accuracy: 0.6509 - val_loss: 0.3557 - val_accuracy: 0.8276\n",
            "Epoch 48/100\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 0.6081 - accuracy: 0.6521 - val_loss: 0.3572 - val_accuracy: 0.8267\n",
            "Epoch 49/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6060 - accuracy: 0.6568 - val_loss: 0.3538 - val_accuracy: 0.8276\n",
            "Epoch 50/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6024 - accuracy: 0.6631 - val_loss: 0.3560 - val_accuracy: 0.8263\n",
            "Epoch 51/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.6006 - accuracy: 0.6605 - val_loss: 0.3488 - val_accuracy: 0.8330\n",
            "Epoch 52/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6021 - accuracy: 0.6607 - val_loss: 0.3477 - val_accuracy: 0.8356\n",
            "Epoch 53/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5994 - accuracy: 0.6664 - val_loss: 0.3514 - val_accuracy: 0.8281\n",
            "Epoch 54/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5959 - accuracy: 0.6696 - val_loss: 0.3509 - val_accuracy: 0.8321\n",
            "Epoch 55/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5937 - accuracy: 0.6726 - val_loss: 0.3534 - val_accuracy: 0.8241\n",
            "Epoch 56/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5940 - accuracy: 0.6709 - val_loss: 0.3467 - val_accuracy: 0.8392\n",
            "Epoch 57/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5908 - accuracy: 0.6762 - val_loss: 0.3552 - val_accuracy: 0.8210\n",
            "Epoch 58/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5900 - accuracy: 0.6732 - val_loss: 0.3534 - val_accuracy: 0.8299\n",
            "Epoch 59/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5868 - accuracy: 0.6740 - val_loss: 0.3490 - val_accuracy: 0.8396\n",
            "Epoch 60/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5892 - accuracy: 0.6740 - val_loss: 0.3570 - val_accuracy: 0.8267\n",
            "Epoch 61/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.5818 - accuracy: 0.6846 - val_loss: 0.3541 - val_accuracy: 0.8343\n",
            "Epoch 62/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5873 - accuracy: 0.6805 - val_loss: 0.3585 - val_accuracy: 0.8254\n",
            "Epoch 63/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5810 - accuracy: 0.6891 - val_loss: 0.3594 - val_accuracy: 0.8263\n",
            "Epoch 64/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5779 - accuracy: 0.6856 - val_loss: 0.3555 - val_accuracy: 0.8498\n",
            "Epoch 65/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.5795 - accuracy: 0.6850 - val_loss: 0.3604 - val_accuracy: 0.8401\n",
            "Epoch 66/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5746 - accuracy: 0.6841 - val_loss: 0.3656 - val_accuracy: 0.8347\n",
            "Epoch 67/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5740 - accuracy: 0.6914 - val_loss: 0.3674 - val_accuracy: 0.8476\n",
            "Epoch 68/100\n",
            "61/61 [==============================] - 4s 70ms/step - loss: 0.5722 - accuracy: 0.6852 - val_loss: 0.3680 - val_accuracy: 0.8454\n",
            "Epoch 69/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.5740 - accuracy: 0.6899 - val_loss: 0.3707 - val_accuracy: 0.8307\n",
            "Epoch 70/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5720 - accuracy: 0.6921 - val_loss: 0.3669 - val_accuracy: 0.8481\n",
            "Epoch 71/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5662 - accuracy: 0.6976 - val_loss: 0.3699 - val_accuracy: 0.8467\n",
            "Epoch 72/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5640 - accuracy: 0.7007 - val_loss: 0.3807 - val_accuracy: 0.8241\n",
            "Epoch 73/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5639 - accuracy: 0.6975 - val_loss: 0.3748 - val_accuracy: 0.8490\n",
            "Epoch 74/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5657 - accuracy: 0.6996 - val_loss: 0.3821 - val_accuracy: 0.8432\n",
            "Epoch 75/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5647 - accuracy: 0.6942 - val_loss: 0.3771 - val_accuracy: 0.8467\n",
            "Epoch 76/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5595 - accuracy: 0.7044 - val_loss: 0.3804 - val_accuracy: 0.8405\n",
            "Epoch 77/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5586 - accuracy: 0.7051 - val_loss: 0.3877 - val_accuracy: 0.8494\n",
            "Epoch 78/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5612 - accuracy: 0.7001 - val_loss: 0.3913 - val_accuracy: 0.8392\n",
            "Epoch 79/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5535 - accuracy: 0.7046 - val_loss: 0.3843 - val_accuracy: 0.8401\n",
            "Epoch 80/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5530 - accuracy: 0.7145 - val_loss: 0.3923 - val_accuracy: 0.8458\n",
            "Epoch 81/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5507 - accuracy: 0.7128 - val_loss: 0.3916 - val_accuracy: 0.8472\n",
            "Epoch 82/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.5440 - accuracy: 0.7129 - val_loss: 0.4031 - val_accuracy: 0.8458\n",
            "Epoch 83/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5468 - accuracy: 0.7151 - val_loss: 0.4056 - val_accuracy: 0.8432\n",
            "Epoch 84/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5447 - accuracy: 0.7161 - val_loss: 0.4126 - val_accuracy: 0.8458\n",
            "Epoch 85/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5364 - accuracy: 0.7201 - val_loss: 0.4035 - val_accuracy: 0.8365\n",
            "Epoch 86/100\n",
            "61/61 [==============================] - 4s 70ms/step - loss: 0.5383 - accuracy: 0.7176 - val_loss: 0.4142 - val_accuracy: 0.8387\n",
            "Epoch 87/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5372 - accuracy: 0.7124 - val_loss: 0.4133 - val_accuracy: 0.8352\n",
            "Epoch 88/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5370 - accuracy: 0.7213 - val_loss: 0.4128 - val_accuracy: 0.8321\n",
            "Epoch 89/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5334 - accuracy: 0.7203 - val_loss: 0.4273 - val_accuracy: 0.8285\n",
            "Epoch 90/100\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.5286 - accuracy: 0.7291 - val_loss: 0.4145 - val_accuracy: 0.8334\n",
            "Epoch 91/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5288 - accuracy: 0.7200 - val_loss: 0.4154 - val_accuracy: 0.8294\n",
            "Epoch 92/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5291 - accuracy: 0.7222 - val_loss: 0.4145 - val_accuracy: 0.8290\n",
            "Epoch 93/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5303 - accuracy: 0.7244 - val_loss: 0.4153 - val_accuracy: 0.8281\n",
            "Epoch 94/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5247 - accuracy: 0.7309 - val_loss: 0.4057 - val_accuracy: 0.8294\n",
            "Epoch 95/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5236 - accuracy: 0.7231 - val_loss: 0.4123 - val_accuracy: 0.8227\n",
            "Epoch 96/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5201 - accuracy: 0.7337 - val_loss: 0.4019 - val_accuracy: 0.8299\n",
            "Epoch 97/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5208 - accuracy: 0.7341 - val_loss: 0.4101 - val_accuracy: 0.8259\n",
            "Epoch 98/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5166 - accuracy: 0.7357 - val_loss: 0.4101 - val_accuracy: 0.8236\n",
            "Epoch 99/100\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.5157 - accuracy: 0.7320 - val_loss: 0.4181 - val_accuracy: 0.8223\n",
            "Epoch 100/100\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5131 - accuracy: 0.7382 - val_loss: 0.4099 - val_accuracy: 0.8223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d0eaba198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WGAI9sTNM4j9"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "training = tf.compat.v1.placeholder(tf.bool,name='phase_train')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}