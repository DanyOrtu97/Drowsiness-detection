{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "pycharm-43a80b0",
      "language": "python",
      "display_name": "PyCharm (ProgettoDLA-Puglisi-)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Benchmarker.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gkLYv6HBM4j6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLqUgMAyQ9Xk"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QT-7Ab32M4j7"
      },
      "source": [
        "Blinks = np.load('/content/drive/MyDrive/DLA/npy/Blinks_F3.npy')\n",
        "Labels = np.load('/content/drive/MyDrive/DLA/npy/Labels_F3.npy')\n",
        "BlinksTest = np.load('/content/drive/MyDrive/DLA/npy/BlinksTest_F3.npy')\n",
        "LabelsTest = np.load('/content/drive/MyDrive/DLA/npy/LabelsTest_F3.npy')\n",
        "    #deciding the indices of each video based on the fold\n",
        "    #####################Normalizing the input#############Second phase\n",
        "BlinksTest[:,:,0]=(BlinksTest[:,:,0]-np.mean(Blinks[:,:,0]))/np.std(Blinks[:,:,0])\n",
        "Blinks[:,:,0]=(Blinks[:,:,0]-np.mean(Blinks[:,:,0]))/np.std(Blinks[:,:,0])\n",
        "    #####\n",
        "    #####\n",
        "BlinksTest[:,:,1]=(BlinksTest[:,:,1]-np.mean(Blinks[:,:,1]))/np.std(Blinks[:,:,1])\n",
        "Blinks[:,:,1]=(Blinks[:,:,1]-np.mean(Blinks[:,:,1]))/np.std(Blinks[:,:,1])\n",
        "    #####\n",
        "BlinksTest[:,:,2]=(BlinksTest[:,:,2]-np.mean(Blinks[:,:,2]))/np.std(Blinks[:,:,2])\n",
        "Blinks[:,:,2]=(Blinks[:,:,2]-np.mean(Blinks[:,:,2]))/np.std(Blinks[:,:,2])\n",
        "    #####\n",
        "BlinksTest[:,:,3]=(BlinksTest[:,:,3]-np.mean(Blinks[:,:,3]))/np.std(Blinks[:,:,3])\n",
        "Blinks[:,:,3]=(Blinks[:,:,3]-np.mean(Blinks[:,:,3]))/np.std(Blinks[:,:,3])\n",
        "    ####\n",
        "    ####JUST TO DOUBLE CHECK\n",
        "    ####\n",
        "    # print(np.mean(Blinks[:,:,0]),np.mean(Blinks[:,:,1]),np.mean(Blinks[:,:,2]),np.mean(Blinks[:,:,3]))\n",
        "    # print(np.std(Blinks[:,:,0]),np.std(Blinks[:,:,1]),np.std(Blinks[:,:,2]),np.std(Blinks[:,:,3]))\n",
        "    # print(np.mean(BlinksTest[:,:,0]),np.mean(BlinksTest[:,:,1]),np.mean(BlinksTest[:,:,2]),np.mean(BlinksTest[:,:,3]))\n",
        "    # print(np.std(BlinksTest[:,:,0]),np.std(BlinksTest[:,:,1]),np.std(BlinksTest[:,:,2]),np.std(BlinksTest[:,:,3]))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXPk40ffK_iw"
      },
      "source": [
        "#BinarizationLabels\r\n",
        "LabelsTest[LabelsTest==10] = 1\r\n",
        "Labels[Labels==10] = 1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4QvMI1ELM4j8"
      },
      "source": [
        "def create_model(model_name):\n",
        "    if model_name == 'LSTMreza':\n",
        "      input = tf.keras.Input(shape=(30, 4))\n",
        "      x = tf.keras.layers.Dense(64, activation='relu')(input)\n",
        "      x = tf.keras.layers.Masking(mask_value=0.0)(x)\n",
        "      x = tf.keras.layers.LSTM(32, return_sequences=False,dropout=0.1, recurrent_dropout=0.1)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(8, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.1)(x)\n",
        "      y = tf.keras.layers.Dense(1, activation='tanh')(x)\n",
        "      model = tf.keras.models.Model(inputs=[input], outputs=[y])\n",
        "    elif model_name == 'LSTM':\n",
        "      input = tf.keras.Input(shape=(30, 4))\n",
        "      x = tf.keras.layers.Masking(mask_value=0.0)(input)\n",
        "      x = tf.keras.layers.LSTM(32, return_sequences=False,dropout=0.1, recurrent_dropout=0.1)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.5)(x)\n",
        "      y = tf.keras.layers.Dense(1, activation='tanh')(x)\n",
        "      model = tf.keras.models.Model(inputs=[input], outputs=[y])\n",
        "    elif model_name == 'stackedreza':\n",
        "      input = tf.keras.Input(shape=(30, 4))\n",
        "      x = tf.keras.layers.Dense(64, activation='relu')(input)\n",
        "      x = tf.keras.layers.Masking(mask_value=0.0)(x)\n",
        "      rnn_cells = [tf.keras.layers.LSTMCell(32, dropout=0.1, recurrent_dropout=0.1) for _ in range(4)]\n",
        "      stacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)\n",
        "      x = tf.keras.layers.RNN(stacked_lstm)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(8, activation='relu')(x)\n",
        "      x = tf.keras.layers.Dropout(0.1)(x)\n",
        "      y = tf.keras.layers.Dense(1, activation='tanh')(x)\n",
        "      model = tf.keras.models.Model(inputs=[input], outputs=[y])\n",
        "    else:\n",
        "      print(\"Chiama le cose con il loro nome\")\n",
        "    return model"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTyY8Q7WQWAe"
      },
      "source": [
        "model_name = \"stackedreza\"\r\n",
        "model = create_model(model_name)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6zYeqvFQaBl",
        "outputId": "95e6fd7b-cb65-42bc-fffe-d2dc66938c70"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 30, 4)]           0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 30, 64)            320       \n",
            "_________________________________________________________________\n",
            "masking_17 (Masking)         (None, 30, 64)            0         \n",
            "_________________________________________________________________\n",
            "rnn_11 (RNN)                 (None, 32)                37376     \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 38,641\n",
            "Trainable params: 38,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08YWVpLJQjgB"
      },
      "source": [
        "lr = 0.000053\r\n",
        "bs = 64\r\n",
        "ep = 80\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \r\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\r\n",
        "              metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt592QOSQn4V",
        "outputId": "e7b54c10-7d31-4c88-aef4-af2b68886c37"
      },
      "source": [
        "model.fit(x= Blinks, y = Labels, validation_data=(BlinksTest, LabelsTest), epochs=ep, batch_size=bs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "121/121 [==============================] - 30s 163ms/step - loss: 1.7782 - accuracy: 0.4474 - val_loss: 1.6688 - val_accuracy: 0.2994\n",
            "Epoch 2/80\n",
            "121/121 [==============================] - 19s 161ms/step - loss: 1.0469 - accuracy: 0.4672 - val_loss: 0.7380 - val_accuracy: 0.4038\n",
            "Epoch 3/80\n",
            "121/121 [==============================] - 19s 160ms/step - loss: 0.7752 - accuracy: 0.5442 - val_loss: 0.6584 - val_accuracy: 0.6775\n",
            "Epoch 4/80\n",
            "121/121 [==============================] - 19s 158ms/step - loss: 0.7219 - accuracy: 0.5469 - val_loss: 0.6245 - val_accuracy: 0.7645\n",
            "Epoch 5/80\n",
            "121/121 [==============================] - 19s 157ms/step - loss: 0.7348 - accuracy: 0.5383 - val_loss: 0.5938 - val_accuracy: 0.7379\n",
            "Epoch 6/80\n",
            "121/121 [==============================] - 19s 158ms/step - loss: 0.7080 - accuracy: 0.5481 - val_loss: 0.5721 - val_accuracy: 0.7819\n",
            "Epoch 7/80\n",
            "121/121 [==============================] - 19s 157ms/step - loss: 0.7186 - accuracy: 0.5594 - val_loss: 0.5432 - val_accuracy: 0.7868\n",
            "Epoch 8/80\n",
            "121/121 [==============================] - 19s 161ms/step - loss: 0.7087 - accuracy: 0.5547 - val_loss: 0.5144 - val_accuracy: 0.7934\n",
            "Epoch 9/80\n",
            "121/121 [==============================] - 19s 158ms/step - loss: 0.6951 - accuracy: 0.5679 - val_loss: 0.4763 - val_accuracy: 0.7939\n",
            "Epoch 10/80\n",
            "121/121 [==============================] - 19s 159ms/step - loss: 0.6877 - accuracy: 0.5902 - val_loss: 0.4421 - val_accuracy: 0.7868\n",
            "Epoch 11/80\n",
            "121/121 [==============================] - 19s 156ms/step - loss: 0.6739 - accuracy: 0.6092 - val_loss: 0.4150 - val_accuracy: 0.7868\n",
            "Epoch 12/80\n",
            "121/121 [==============================] - 20s 162ms/step - loss: 0.6627 - accuracy: 0.6096 - val_loss: 0.3904 - val_accuracy: 0.7881\n",
            "Epoch 13/80\n",
            "121/121 [==============================] - 19s 157ms/step - loss: 0.6620 - accuracy: 0.6248 - val_loss: 0.3730 - val_accuracy: 0.8028\n",
            "Epoch 14/80\n",
            "121/121 [==============================] - 19s 158ms/step - loss: 0.6416 - accuracy: 0.6497 - val_loss: 0.3718 - val_accuracy: 0.7934\n",
            "Epoch 15/80\n",
            "121/121 [==============================] - 19s 159ms/step - loss: 0.6565 - accuracy: 0.6397 - val_loss: 0.3671 - val_accuracy: 0.7992\n",
            "Epoch 16/80\n",
            "121/121 [==============================] - 19s 155ms/step - loss: 0.6370 - accuracy: 0.6433 - val_loss: 0.3644 - val_accuracy: 0.7974\n",
            "Epoch 17/80\n",
            "121/121 [==============================] - 19s 156ms/step - loss: 0.6340 - accuracy: 0.6546 - val_loss: 0.3636 - val_accuracy: 0.7992\n",
            "Epoch 18/80\n",
            "121/121 [==============================] - 19s 156ms/step - loss: 0.6326 - accuracy: 0.6588 - val_loss: 0.3538 - val_accuracy: 0.8219\n",
            "Epoch 19/80\n",
            "121/121 [==============================] - 19s 161ms/step - loss: 0.6118 - accuracy: 0.6593 - val_loss: 0.3512 - val_accuracy: 0.8272\n",
            "Epoch 20/80\n",
            "121/121 [==============================] - 19s 159ms/step - loss: 0.6238 - accuracy: 0.6595 - val_loss: 0.3590 - val_accuracy: 0.8081\n",
            "Epoch 21/80\n",
            "121/121 [==============================] - 19s 160ms/step - loss: 0.6098 - accuracy: 0.6686 - val_loss: 0.3492 - val_accuracy: 0.8423\n",
            "Epoch 22/80\n",
            "121/121 [==============================] - 20s 162ms/step - loss: 0.6079 - accuracy: 0.6735 - val_loss: 0.3617 - val_accuracy: 0.8147\n",
            "Epoch 23/80\n",
            "121/121 [==============================] - 19s 160ms/step - loss: 0.5963 - accuracy: 0.6809 - val_loss: 0.3684 - val_accuracy: 0.8152\n",
            "Epoch 24/80\n",
            "121/121 [==============================] - 20s 161ms/step - loss: 0.6032 - accuracy: 0.6745 - val_loss: 0.3909 - val_accuracy: 0.8036\n",
            "Epoch 25/80\n",
            "121/121 [==============================] - 19s 158ms/step - loss: 0.5989 - accuracy: 0.6745 - val_loss: 0.3968 - val_accuracy: 0.8214\n",
            "Epoch 26/80\n",
            "121/121 [==============================] - 20s 161ms/step - loss: 0.5997 - accuracy: 0.6752 - val_loss: 0.4334 - val_accuracy: 0.7952\n",
            "Epoch 27/80\n",
            "  8/121 [>.............................] - ETA: 17s - loss: 0.6031 - accuracy: 0.6532"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WGAI9sTNM4j9"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "training = tf.compat.v1.placeholder(tf.bool,name='phase_train')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}